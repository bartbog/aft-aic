%% \todo{Some complexity results.
%% Probably: well-founded/KK: polynomially computable (data complexity), stable fixpoints: NP-complete, ... Copy results from logic programming basically. Similarly, complexity increases if we start using ultimate approximators}
\ignore{
In this section, we study complexity of some tasks related to AFT-style semantics for active integrity constraints. 
Before we do so, we provide a new complexity result for logic programs, that we will use later on in our proofs. 

\subsection{A Novel Complexity Result for Logic Programming} 

In this section, we show that deciding whether a \emph{simple} logic program has a grounded fixpoint is $\Sigma^P_2$-complete by establishing a reduction from the problem for arbitrary normal logic programs. 
The intuition is simply to duplicate every atom $a$ as $a^b$ and $a^h$, to be used (only) in bodies or heads of rules, respectively, and add the necessary rules to ensure that they have the same interpretation in any fixpoint of the immediate consequence operator.

We assume the set $\atoms$ to be fixed and denote by $\atoms^*$ the set $\{a^h,a^b\mid a \in \atoms\}$; for $I\subseteq\atoms$. 
We extend the mappings $\cdot^h:\atoms \to \atoms^*$ and $\cdot^b:\atoms \to \atoms^*$ to sets and formulas 
in the natural way, e.g., $I^b=\{a^b\mid a\in I\}$ and  if $p,q\in \atoms$, then $(p\land \lnot q)^b = p^b\land \lnot q^b$. 
If $I$ is an $\atoms^*$-interpretation, i.e., a subset of $\atoms^*$,  we define $I|_h$ and $I|_b$ as the $\atoms$-interpretation $I|_h=\{a\mid a^h\in I\}$  and $I|_b=\{a\mid a^b\in I\}$. 

\begin{definition}
  Let $\PP$ be a logic program.
  Its simple counterpart is the logic program $\PP^s$ over $\atoms^*$ consisting of:
  \begin{itemize}
  %\item for each rule $a\leftarrow l_1,\ldots,l_n$ from $\PP$, the rule $a^h\leftarrow l^b_1,\ldots,l^b_n$;
  \item for each rule $r\in\PP$, the rule $\head(r)^h\leftarrow\body(r)^b$;
  \item rules $a^b\leftarrow a^h$ for each $a\in\voc$.
  \end{itemize}
\end{definition}

The programs $\PP$ and $\PP^s$ are closely related. The following lemmas and propositions study this relationship. 

\begin{lemma}
  \label{lem:op-simple}
  For each $\atoms^*$ interpretation  $I$, it holds that 
  \[ T_{\PP^s}\left(I\right) = \left(T_\PP(I|_b)\right)^h\cup (I|_h)^b.\]
\end{lemma}
\begin{proof}
Follows directly by unfolding the definition of $\PP^s$. Indeed,
  \begin{align*}
    T_{\PP^s}\left(I\right) &= \{\head(r)\mid r\in \PP^s\land \body(r)^I=\ltrue\} \\
    &= \{\head(r)^h\mid r\in \PP \land (\body(r)^b)^{I}=\ltrue\}\cup\{a^b\mid a^h\in I\} \\
    &= \{\head(r)^h\mid r\in \PP \land (\body(r))^{I|_b}=\ltrue\}\cup (I|_h)^b \\
    &= \left(T_\PP(I|_b)\right)^h\cup (I|_h)^b.\qedhere
  \end{align*}
\end{proof}

\begin{proposition}
  \label{prop:simple-fp}
  Let $I$ be an $\atoms^*$-interpretation. It holds that $I$ is a fixpoint of  $T_{\PP^s}$ if and only if $I|_b=I|_h$ and $I|_h$ is a fixpoint of $T_\PP$.
\end{proposition}
\begin{proof}
If $I$ is a fixpoint of $T_{\PP^s}$, then since the only rules defining atoms of the form $a^b$ are the rule $a^b\lrule a^h$, it follows that  $I|_b=I|_h$. 
Now, in this case, it follows from Lemma \ref{lem:op-simple} that 
\[ T_{\PP^s}\left(I\right) = \left(T_\PP(I|_b)\right)^h\cup (I|_b)^h = I .\]
Hence, also 
\[\left(T_\PP(I|_b)\right)^h=I|b^h\]
and indeed $I|_b$ (which equals $I|_h$) is a fixpoint of $T_\PP$. 

On the other hand, if $I|_h=I|_b$ and $I|_h$ is a fixpoint of $T_\PP$, it is easy to see that $I$ is a fixpoint of $T_{\PP^s}$.
% 
% 
%   If $I^h\cup J^b=T_{\PP^s}\left(I^h\cup J^b\right)=T_\PP(J)^h\cup I^b$, then necessarily $I^h=T_\PP(J)^h$ and $J^b=I^b$.
%   From the latter equality we conclude that $I=J$, whence the former yields $I=T_\PP(J)=T_\PP(I)$.
\end{proof}


\begin{proposition}
  \label{prop:simple-gf}
    Let $I$ be an $\atoms^*$-interpretation. It holds that $I$ is a grounded fixpoint of  $T_{\PP^s}$ if and only if $I|_b=I|_h$ and $I|_h$ is a grounded fixpoint of $T_\PP$.
\end{proposition}
\begin{proof}
  Since grounded and strictly grounded fixpoints coincide for Boolean lattices \mycite{GroundedFixpoints}, we can use the definition  of strictly grounded fixpoints in this proof.

  First suppose $I$ is a grounded fixpoint of $T_{\PP^s}$.
  By Proposition \ref{prop:simple-fp}, $I|_b=I|_h$ and $I|_h$ is a fixpoint of $T_\PP$. We need to show $I|_h$ is grounded. 
  Let $J\subsetneq I|_h$ be such that $T_\PP(J)\cap I|_h\subseteq J$.
  Using Lemma~\ref{lem:op-simple}, we have that
  \begin{align*}
    T_{\PP^s}\left(J^h\cup J^b\right)\cap\left(I\right) &=
    \left(T_\PP(J)^h\cup J^b\right)\cap\left(I\right) \\
    &= (\underbrace{T_\PP(J)^h\cap I}_{\subseteq J^h})\cup(\underbrace{J^b\cap I}_{\subseteq J^b}) \\
    &\subseteq J^h\cup J^b.   
  \end{align*}
  Now, since $J\subsetneq I|_h$ and $I|_h=I|_b$, also $J^h\cup J^b \subsetneq I$. Hence, the previous equation contradicts contradicting the fact that $I$ is a grounded fixpoint of $T_{\PP^s}$.

  Conversely, suppose that $I|_b=I|_h$ and $I|_h$ is a grounded fixpoint of $T_\PP$. 
  Consider an arbitrary $J\subsetneq I$. 
  It follows from Proposition~\ref{prop:simple-fp} that $I^h\cup I^b$ is a fixpoint of $T_{\PP^s}$.
  Again using Lemma~\ref{lem:op-simple}, we also have that
  \begin{align*}
    T_{\PP^s}\left(J\right)\cap\left(I\right) &=
    \left(T_\PP(J|_b)^h\cup J_h^b\right)\cap\left(I\right) \\
    &= (T_\PP(J|_b)^h\cap I)\cup(J_1^b\cap I)
  \end{align*}
  \todo{bart from here}

  If this is a subset of $J_1^h\cup J_2^b$, then we conclude that $T_\PP(J_2)^h\cap I^h\subseteq J_1^h$ and $J_1^b\cap I^b\subseteq J_2^b$, which imply that
  $T_\PP(J_2)\cap I\subseteq J_1$ and $J_1\cap I\subseteq J_2$.
  Then $T_\PP(J_2)\cap I\subseteq J_1\cap I\subseteq J_2$.
  Furthermore, if $J_2=I$, then the fact that $T_\PP(I)=I$ would imply that also $J_1=I$, contradicting $J_1^h\cup J_2^b\subsetneq I^h\cup I^b$.
  Therefore $I$ is not a grounded fixpoint of $T_\PP$.
\end{proof}

Combining Propositions~\ref{prop:simple-fp} and~\ref{prop:simple-gf}, we obtain a characterization of all grounded fixpoints of $\PP^s$.

\begin{corollary}
  $I^h\cup J^b$ is a grounded fixpoint of $T_{\PP^s}$ iff $I=J$ and $I$ is a grounded fixpoint of $T_\PP$.
\end{corollary}

Furthermore, since $\PP^s$ can be constructed from $\PP$ in polynomial time, we also obtain a complexity result.

\begin{corollary}
  \label{cor:simple-has-gf}
  The problem of deciding whether a simple logic program has a grounded fixpoint is $\Sigma^P_2$-complete.
\end{corollary}


\subsection{Complexity of AFT-style semantics for AICs}
}
% \todo{streamline section}


We begin this section by stating an observation about the complexity of computing \Ap.
All complexity results are in terms of the size of the database, \fulldb.
% In the entire section, we assume $\aics$ and \atoms are finite. 
\begin{proposition}
  \label{prop:At-poly}
  Given a partial action set \UUU, 
  $\Ap(\UUU)$ is computable in polynomial time. % on the size of 
\end{proposition}
\begin{proof}
    The definition of \Ap only requires evaluating $\UUU(a)$, $\suppin_{\UUU}(a)$ and $\suppout_{\UUU}(a)$ for each $a\in\atoms$.
    In turn, the two last computations can be done in polynomial time: they require evaluating each literal in the body of each rule from $\eta$ with head $\add a$ or $\remove a$ and computing its truth value under the database updated by $\UUU$.
\end{proof}

\begin{proposition}
  \label{prop:grounded-complexity}
  Let $\db$ be a database and $\eta$ be a set of normal AICs over $\db$.
  The problem of deciding whether there exists a  grounded repair for $\fulldb$ is $\Sigma^P_2$-complete.
\end{proposition}
\begin{proof}
  \emph{(Inclusion)} We need to show that we can decide the problem with a non-deterministic Turing machine with an NP oracle.
  Given a set of update actions $\UU$, checking that it is a fixpoint of $\Op$ can be done in polynomial time on the size of $\db$ and $\eta$, as shown in Proposition~\ref{prop:At-poly}; the NP-oracle can then answer whether there exists $\UU'\subsetneq\UU$ with $\Op(\UU')\cap\UU\subseteq\UU'$, thereby establishing whether $\UU$ is grounded.

  \emph{(Hardness)}
  We show hardness directly by reducing another $\Sigma^P_2$-hard problem to deciding whether a particular database with a set of AICs has a grounded repair.  Our proof is a straightforward adaptation of~\citep[Theorem~5.7]{ai/BogaertsVD15}, which in turn is inspired by~\citep[Theorem 6.12]{DeneckerMT04}.

  Given a DNF formula $\varphi$ over  propositional symbols $x_1,\ldots,x_m,y_1,\ldots,y_n$, and an interpretation $I$ of the $x_i$, let $\varphi_I$ denote the formula obtained by replacing each occurrence of $x_i$ with either $\ltrue$, if $x_i\in I$, or $\lfalse$, otherwise. 
  The problem to decide whether there exists an interpretation $I$ of the $x_i$ such that $\varphi_I$ is a tautology is $\Sigma^P_2$ hard. We now reduce this problem to our problem. 
  
  We consider the empty database $\db$ over $\atoms=\{x_i,x'_i\mid 1\leq i\leq m\}\cup\{p,q,y_1,\ldots,y_n\}$, where we use $x'_i$ to represent the negation of $x_i$.  We write $\varphi'$ for the formula obtained by uniformly replacing $\neg x_i$ with $x'_i$ in $\varphi$.  The set of AICs $\eta(\varphi)$ is defined as follows, where we assume $\varphi'=\varphi'_1\lor\ldots\lor \varphi'_k$ and each $\varphi'_i$ is a conjunction of literals.
  \begin{align}
    \neg x_i\land\neg x'_i &\aicrule \add x_i & \neg x_i\land\neg x'_i &\aicrule \add x'_i & \text{for } 1\leq i\leq m & \label{rules1} \\
    \varphi'_i\land\neg y_j &\aicrule \add y_j & \varphi'_i \land \neg p &\aicrule \add p & \text{for }1\leq i\leq k, 1\leq j\leq n & \label{rules2} \\
    \neg p,\neg q &\aicrule \add q & \neg p,q &\aicrule \remove q & \label{rules3}
  \end{align}
  The following properties hold about $\eta(\varphi)$.
  \newcommand\dbhere{\m{\langle\eta(\varphi),\emptyset\rangle}}
  \begin{itemize}
   \item[a.] Each weak repair of \dbhere contains $\add p$ (otherwise one of the rules \ref{rules3} would apply).
   \item[b.] No repair  for \dbhere contains $\add q$ (due to minimality). 
   \item[c.] In each grounded repair for \dbhere, at least one of the $\varphi_i'$ is satisfied (otherwise, removing $\add p$ from that repair would result in a set of update actions where $\add p$ is no longer derivable, contradicting groundedness). 
   \item[d.] Each grounded repair for \dbhere contains all of the $\add y_j$ (follows directly from the previous point). 
   \item[e.] Each grounded repair for \dbhere contains for each $i$, exactly one of $\add x_i$ and $\add x_i'$ (it must contain at least one due to rules \ref{rules1}; the previous points guarantee that rules \ref{rules2} and \ref{rules3} are satisfied regardless of the $x_i$ and $x_i'$ in each grounded repair, hence minimality implies that it can contain at most one of these two actions). 	
  \end{itemize}
  Given an interpretation $I$, we write $\check I$ to denote the set $\{\add x_i\mid x_i\in I\}\cup\{\add x'_i\mid x_i\notin I\}$.
  From observations a-e above, it follows that all grounded fixpoints for \dbhere must be of the form  $\UU_I=\check I\cup\{p,y_1,\ldots,y_n\}$ for some interpretation $I$ of the $x_i$. We now show that for each interpretation $I$, $\UU_I$ is a grounded repair for $\dbhere$ iff $\varphi_I$ is a tautology. 
%   Observe that this set is always a weak repair for $\dbhere$.
  \begin{itemize}
  \item First, assume that $\UU_I$ is a grounded repair of $\dbhere$.
    If $J\subseteq\{y_1,\ldots,y_n\}$ is a falsifying assignment for $\varphi_I$, then $T_{\eta(\varphi)}(\check I\cup\{\add y_i\mid y_i\in J\})\cap\UU=(\check I\cup\{\add y_i\mid y_i\in J\}\cup\{\add q\})\cap\UU=\check I\cup\{\add y_i\mid y_i\in J\}$, contradicting the fact that $\UU$ is a grounded repair for $\dbhere$.
    (Note that $\check I\cup\{\add y_i\mid y_i\in J\}$ is always a strict subset of $\UU$, since it does not contain $p$.)
    Therefore $\varphi_I$ is a tautology.
  \item Suppose on the other hand that $\varphi_I$ is a tautology.
    Let $\VV\subseteq\UU$ be such that $T_{\eta(\varphi)}(\VV)\cap\UU\subseteq\VV$.
    If $\add x_i\in(\UU\setminus\VV)$ or  $\add x_i'\in(\UU\setminus\VV)$ for some $i$, then $\add x_i\in T_{\eta(\varphi)}(\VV)$ by rules \ref{rules1}; therefore, $\check I\subseteq\VV$.
    But $\varphi_I$ is a tautology, hence if $\add y_i\notin\VV$, then the corresponding rule from~\ref{rules2} ensures that $\add y_i\in T_{\eta(\varphi)}(\VV)$. Likewise, if $\add p\notin\VV$, then $\add p\in T_{\eta(\varphi)}(\VV)$.
    We thus conclude that $\VV=\UU$, whence $\UU$ is a grounded repair for $\dbhere$.\qedhere
  \end{itemize}
\end{proof}

% As a consequence, we get the following complexity results.
\begin{proposition}
  The Kripke-Kleene repair for $\fulldb$ is computable in polynomial time.
  \label{prop:KK-poly}
\end{proposition}
\begin{proof}
  The Kripke-Kleene repair of $\fulldb$ can be computed by iterating $\Ap$ until a fixpoint is reached.
  Since $\Ap$ is monotonic, the maximum number of iterations is the size of $\atoms$; since each iteration can be computed in polynomial time (Proposition~\ref{prop:At-poly}), so can this fixpoint.
\end{proof}

\begin{proposition}\label{prop:compl:wf}
  The ATF-well-founded repair for $\fulldb$ is computable in polynomial time.
\end{proposition}

The proof makes use of the following proposition. 
\begin{proposition}[\citeauthor{lpnmr/DeneckerV07},~\citeyear{lpnmr/DeneckerV07}]\label{prop:biggestufs}
Let $A$ be an approximator of $O$ and $(x,y)\in L^2$. 
Let $S_A^x$ be the operator on $L$ that maps every $y'$ to $A(x,y')_2$.
This operator is monotone. 
The smallest $y'$ such that $(x,y')$ is an unfoundedness refinement of $(x,y)$ is given by 
$y'=\lfp (S_A^x)$.
 \end{proposition}
 \begin{proof}[Proof of Proposition \ref{prop:compl:wf}]
 To compute the \Ap-well-founded fixpoint, we can construct a well-founded induction with only strict refinements. 
 Since such a well-founded is $\leqp$-increasing, it can consist of at most of $|\atoms|$ steps. 
 Computing if there exists a strict application refinement of a given partial repair set \UUU
can be done by computing $\Ap(\UUU)$. Now, Proposition \ref{prop:biggestufs} shows that the most precise unfoundedness refinement can also be computed as the least fixpoint of a derived operator on $2^\atoms$. Such a fixpoint can again be computed in polynomial time. Hence, it follows that we can compute a terminal well-founded induction, and thus the well-founded fixpoint, in polynomial time. 
%  
%   \luis{not sure about this one: Bart writes ``a well-founded induction runs in polytime in the height of the lattice if computing $A(x,y)$ can be done in polytime''.  So it should follow from Proposition~\ref{prop:At-poly}, but I'm missing the argument (I only get NP).}
\end{proof}

\begin{proposition}\label{prop:stable-complexity}
  The task of checking if a database $\fulldb$ has a stable repair is NP-complete.
\end{proposition}
\begin{proof}
  \emph{(Inclusion)} Given a candidate repair, checking that it is stable can be done in polynomial time, as it amounts to verifying that it is a repair (two-valued) and that it is a least fixpoint of the operators $\Ap(\cdot,y)_1$ and $\Ap(x,\cdot)_2$.
  The latter can be done in polynomial time, as in the proof of Proposition~\ref{prop:KK-poly}.

  \emph{(Hardness)} For completeness, we again use the reduction from simple logic programs to AICs from~\cite{tplp/CaropreseT11} given in Definition~\ref{defn:aic-transf}.
  %A simple logic program is one where rules are not trivial tautologies, i.e., they do not contain contradictory atoms in their bodies and they do not include their head in their body.
  %The operator $\aicop$ from~\cite{tplp/CaropreseT11} is defined as follows: if $r$ is the logic programming rule $a\leftarrow \ell_1,\ldots,\ell_n$, then $\aicop(r)$ is ${+a}\leftarrow \ell_1\wedge\ldots\wedge\ell_n\wedge\neg a$.
  %Given a logic program $P$, we define $\aicop(P)=\bigcup\{\aicop(r)\mid r\in P\}$.
  This operator preserves stable semantics by Theorem \ref{thm:partialstable-LP}, and therefore allows us to compute stable models of simple logic programs by first translating them (in linear time) to sets of AICs.
  Since checking whether a logic program has a stable model is NP-complete, we conclude that checking whether a database has a stable repair must be NP-hard.
  Note that every logic program can be transformed in a simple logic program by removing the offending rules without changing its stable semantics.
\end{proof}


% \luis{I tried to write this proof as a chain of if-and-only-ifs, but it didn't work, essentially because it is not the case that all repairs satisfy $\varphi_I$. Feel free to improve.}


What we notice in this section is that complexity for inference tasks related to our semantics is always the same as the complexity of its counterpart in (normal) logic programming. 
This illustrates that the added expressivity (essentially, allowing AICs that are not unipolar) does not result in added complexity. 

%% \bart{vague... What do you mean here? }
%% \luis{In the original work, AICs are first-order things that represent the set of all their closed instances. This can give an exponential reduction in the size of $\eta$. I'm trying to say that the complexity still remains the same, because you don't need to compute that set. Maybe we can just ignore this point.}
%% \bart{Ah, I didn't read that. First order things with simple bodies (no arbitrary FO formulas, but universally quantified rules I guess. We can say something about that, but need to be careful: our complexity results change to DATA complexity results than, since by blowing up the number of variables, we can get more exponential behaviour}
%% \bart{If we say this, at the end or the beginning of the section (holds for all results of this section)}
%% \luis{Moved it to the end. The sentence still needs to be fixed.}


Contrary to the original work introducing AICs \cite{ppdp/FlescaGZ04}, our definitions do not include first-order quantifications. 
When allowing such a richer syntax, the results presented in this section can be re-used and constitute data-complexity results. 
% These result still holds if we allow a truly first-order syntax for AICs, where the atoms can include variables that are implictly universally quantified.





%% \bart{Lower bound for stable: every normal logic program can be seen  as an AIC. Should have te same stable smeantics (note: our transformation in theprevious section adds rules 
%% \[a\lrule a\] but these do not change stable models. 

%% Lower bounds for KK well-founded. Well...polytime upper bound is al that needs to be sshown?}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../AFT-semantics-AIC.tex"
%%% End:
